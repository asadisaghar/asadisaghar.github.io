---
layout: post
title: Use tensorflow object detection API to find the RAM in my PC
---

I've been trying to train an object detection model to detect parts of a PC when looking at it. The idea is to constantly monitor this and keep track of part removal, replacement etc. There are many ways to do this, but I have some limitations as well, I strictly want to be able to do everything from python and I want to be able to train my model using the local CPU cluster I have available. After some research on different ways of doing this and the various frameworks and algorithms out there, I cam across what might be my best shot; [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection). This comes with a really good set of tutorials that I followed. However, before getting to the point to use this API, I needed to make some labeled data. My googling around, concluded that there is no easy way of doing it. There are only semi-automated software to do the labeling but all of them consist some few hours of manual labor for the smallest dataset required to train a single-class model, and if it becomes anything more than a prototype or a personal fun project, outsourcing is always as option! So let's start by how I did it for this project.

#### Collect and annotate training data

1- Scrape the web for images of interesting parts/pieces in as many light conditions and from as many angles as possible (especially including in an assembled machine) - I did this by hand, and for a single PC part only. Since I am only making a prototype project and testing if it is going to work at all!

2- Annotate the images with the tool of choice. I used [ImageNet-Utils](https://github.com/tzutalin/ImageNet_Utils). It's simple and fast and easily gives you XML annotations in the pascal VOC format (In fact, it can also output the bbox coordinates in txt files suitable for darknet as well, but I have not used it). It is, however, missing a magic wand tool for object selection.
  * some of the other tools I found interesting along the way:
    - [VGG](http://www.robots.ox.ac.uk/~vgg/software/via/)
    - [LabelD](https://sweppner.github.io/labeld/)
    - [Sloth](https://cvhci.anthropomatik.kit.edu/~baeuml/projects/a-universal-labeling-tool-for-computer-vision-sloth/)
    - [Annotorious](http://annotorious.github.io/)
  * In real life we might want to spend some money and outsource it using , for example, [LabelMe](http://labelme2.csail.mit.edu/Release3.0/browserTools/php/mechanical_turk.php)

Here is a collection of images I used with the boxes.
![Sample of abeled data](../images/2017-10-19-pdm/labeled_data.png)

I probably should have been more consistent in drawing the boxes for images with perspective, but this was something I thought of after having labeled more than half of my photos, so I didn't go back to fix anything!

A couple hours later, I have a dataset of ~130 annotated photo and can move on t the more fun part.

#### Train the model



model training:
´´´
# From tensorflow/models/research/
python object_detection/train.py --logtostderr --pipeline_config_path=/home/saghar/PCguts/PCparts/models/model/ssd_mobilenet_v1_coco.config --train_dir=/home/saghar/PCguts/PCparts/models/model/train/
´´´

model evaluation:
´´´
# From tensorflow/models/research/
python object_detection/eval.py --logtostderr --pipeline_config_path=/home/saghar/PCguts/PCparts/models/model/ssd_mobilenet_v1_coco.config --checkpoint_dir=/home/saghar/PCguts/PCparts/models/model/train/ --eval_dir=/home/saghar/PCguts/PCparts/models/model/eval/
´´´

run tensorboard, sit back and watch (for days!)
´´´
# From tensorflow/models/research/
tensorboard --logdir=/home/saghar/PCguts/PCparts/models/model/
´´´

export the trained model (or a specific checkpoint) to use for inference
´´´
# From tensorflow/models/research/
python object_detection/export_inference_graph.py \
  --input_type image_tensor \
  --pipeline_config_path /home/saghar/PCguts/PCparts/models/model/ssd_mobilenet_v1_coco.config \
  --trained_checkpoint_prefix /home/saghar/PCguts/PCparts/models/model/train/model.ckpt-7125 \
  --output_directory /home/saghar/PCguts/PCparts/output_inference_graph.pb
´´´